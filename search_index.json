[["chapter-3---reading-and-tidying-data.html", "Chapter 3 - Reading and tidying data Learning objectives 0.1 Slides Tidy data The tidyverse Import data Tidy your data Export data The Pipe Additional resources Homework", " Chapter 3 - Reading and tidying data Learning objectives Import data in R Make data tidy with the tidyverse Export data Use the pipe to write clearer code 0.1 Slides Full screen slides Tidy data Tidy data is a set of principles adapted from the relational model (those of you who took my data management course will be familiar with the relational model). The principles are: Each variable forms a column. Each observation forms a row. Each type of observational unit forms a table. You can read more about tidy data the R for Data Science book Wickham and Grolemund (2016), or the journal article by Wickham (2014). The tidyverse The tidyverse is a collection of R packages and functions designed to help you make data tidy and work with tidy data. You can read more about the tidy verse and its packages here: https://www.tidyverse.org. The code below loads the tidyverse and returns the list of packages it includes. library(tidyverse) tidyverse_packages() ## [1] &quot;broom&quot; &quot;cli&quot; &quot;crayon&quot; &quot;dbplyr&quot; ## [5] &quot;dplyr&quot; &quot;dtplyr&quot; &quot;forcats&quot; &quot;googledrive&quot; ## [9] &quot;googlesheets4&quot; &quot;ggplot2&quot; &quot;haven&quot; &quot;hms&quot; ## [13] &quot;httr&quot; &quot;jsonlite&quot; &quot;lubridate&quot; &quot;magrittr&quot; ## [17] &quot;modelr&quot; &quot;pillar&quot; &quot;purrr&quot; &quot;readr&quot; ## [21] &quot;readxl&quot; &quot;reprex&quot; &quot;rlang&quot; &quot;rstudioapi&quot; ## [25] &quot;rvest&quot; &quot;stringr&quot; &quot;tibble&quot; &quot;tidyr&quot; ## [29] &quot;xml2&quot; &quot;tidyverse&quot; In the next sections, we will use a few of the tidyverse packages (but not exclusively) to import data into R from multiple types of source. Because the tidy format is pretty standard and not R-specific, you might often find that the data sets that you will work with are already respecting the tidy principles. But youll also come across different data structures and formats, and so well learn how to tidy up data. Import data The following sections show how to load data from different sources and format into R. Delimited file formats The readr package (https://readr.tidyverse.org/) has a few useful functions for reading delimited file formats like comma-separated values (.csv) and tab-delimited values (.tsv) or any other type of delimiter. Here are a few examples (if you want to run the examples on your computer, you can download the titanic dataset in different formats here. # Imports a comma-separated file and saves it into a data frame called titanic titanic &lt;- read_csv(&quot;tinatic.csv&quot;) # Same, but with a tab-separated file (works with tab-separated .txt files also) titanic &lt;- read_tsv(&quot;titanic.tsv&quot;) # Same, but with a txt file in which the columns are separated with a vertical bar. titanic &lt;- read_delim(&quot;titatic.txt&quot;, delim=&quot;|&quot;) # Same, but reading the file directly from a URL. titanic &lt;- read_csv(&quot;https://pmongeon.github.io/info6270/files/data/titanic.csv&quot;) As you can see from the third example above, you can specify any delimiter using the delim argument of the read_delim function. You should also note that tab-delimited text files (.txt) are extremely common. You can read these files with the read_tsv() function even if the file as the .txt extension. Alternatively, you can use the read_delim() function and use delim = \\t Often, you will see examples where the path to a file is first stored in an object, so the object name, rather than the whole path, can be used in the read_ functions. Like this: path &lt;- &quot;https://pmongeon.github.io/info6270/files/data/titanic.csv&quot; titanic &lt;- read_csv(path) Another useful package is readxl (https://readxl.tidyverse.org/), which has functions to help you read data from Excel files. library(readxl) path &lt;- &quot;https://pmongeon.github.io/info6270/files/data/halifax_weather.xlsx&quot; # This will read the first sheet of the Excel file halifax_weather &lt;- read_xlsx(path) # This will read the second sheet of the Excel file halifax_weather &lt;- read_xlsx(path, sheet = 2) # This will also read the second sheet of the Excel file halifax_weather &lt;- read_xlsx(path, sheet = &quot;out&quot;) # If you don&#39;t know what the names of the sheets are, you can read them like this excel_sheets(path) JSON files The JSON format is very popular for exchanging information on the web, and is the typical format of the data that we retrieve from APIs (next). However the process for reading a JSON file and reading JSON data from an API are slightly different. This is how to convert a JSON file into a data frame using the fromJSON() function from the jsonlite package (included in the tidyverse). library(jsonlite) data &lt;- fromJSON(&quot;https://pmongeon.github.io/info6270/files/data/public_houing_ns.json&quot;) Important note: importing and working with JSON files with simple structures is relatively easy. However, reading more complex JSON files might require a little more work. Reading complex JSON structures is beyond the scope of this chapter. Application programming interface (API) APIs allow you to interact with computers, servers or software by making making different request such as sending or retrieving data through the web. Some APIs can be used for free and anonymously, others might require that you identify your self with your email, for instance, and others will require that you create an account to obtain an api key that you can use in your code. Understanding APIs is beyond the scope of this course, but you should at least know that they exist and that they can be used to collect data for your data science projects. The R package that helps you work with APIs is httr. Below is an example of a request to retrieve data from a free anonymous API. Important note: You do not need to understand how all of the code works. I mainly want you to have a working piece of code that you can use as a template if you ever need to retrieve data from an API. # Load the httr package library(httr) # Make a request to an API to GET data data = GET(&quot;https://openlibrary.org/api/books?bibkeys=OLID:OL22123296M&amp;format=json&quot;) # Isolate the content part of the information received from the API. This step is necessary because the GET request returns additional information about the request along with the requested data data = content(data) # Load the data.table package for the rbindlist() function use in the code below. # You may need to install the package first if you don&#39;t have it installed already. library(data.table) # Converts the data retrieved from the API call to a tibble data = as_tibble(rbindlist(data)) XML files The xml2 package (also included in the tidyverse) provides a set of functions to work with data in the XML format. The conversion of XML data into a data frame is not so straightforward because of the nested structure of the XML. If you need to import XML data in R, the following code performs a series of steps that convert a XML file from data.novascotia.ca website data into a tibble. We will explore this code in more details further in this chapter, when we look more closely at the unnest() function. Important note: the goal here is mainly to provide you with a piece of code that works, so that you can use it as a template to read XML files if you need to and convert them into data frames. library(xml2) path &lt;- &quot;https://data.novascotia.ca/api/views/2d4m-9e6x/rows.xml&quot; public_housing_xml = as_list(read_xml(path)) public_housing = as_tibble(public_housing_xml) public_housing = unnest_longer(public_housing, colnames(public_housing)[1]) public_housing = unnest_wider(public_housing, colnames(public_housing)[1]) public_housing = unnest(public_housing, cols = names(public_housing)) public_housing = unnest(public_housing, cols = names(public_housing)) public_housing = type_convert(public_housing) Connections Important note: This section is a little bit advanced, so please do not feel like you need to master database and file connections at this point in your R journey. I am including this here to raise your awareness of connection and again, give you some working pieces of code that you can use if you ever want or need to access data stored in a large file or database. Connect to a file If you are trying to read a very large file, you may run into issues because the object in your environment are stored in your computers memory (RAM). So if your computer has 4GB of RAM, then files larger than 4GB cant be imported into a data frame, for instance. One solution is to create a connection to the file and then processing the data a certain number of lines at a time. Here is an example. # open the connection to a text file containing data path &lt;- &quot;https://pmongeon.github.io/info6270/files/data/titanic.txt&quot; # open a connection to the file (note that connections are stored as objects) con &lt;- file(path, open=&quot;rb&quot;) # Read the first 10 lines and print them readLines(con, n = 10) # Read the NEXT 10 lines and print them. readLines(con, n=10) # Close the connection to the file. close(con) If you wanted to go through the entire file, 50 lines at a time, and do something. # open the connection to a text file containing data. path &lt;- &quot;https://pmongeon.github.io/info6270/files/data/titanic.txt&quot; con &lt;- file(path, open=&quot;rb&quot;) # this will read 50 lines and print them until the end of the file has been reached. repeat { x&lt;-readLines(con, n = 50) if (is_empty(x) == TRUE) break else print(x) } # Close the connection to the file. close(con) Connect to a database You can also connect to practically all types of local or remote databases and servers as long as you have the required credentials. For example, the RMySQL package is great to work with MySQL databases. You can connect to a MySQL database (provided that you have a user name and password and the other information required by the dbConnect() function). With the RSQLite package, you can also work with local SQL databases stored in a single file on your computer with SQLite. The code below shows you how to connect to MySQL or SQLite databases in R. ## This creates a connection to a MySQL database for which you would need access credentials. library(RMySQL) con = dbConnect(MySQL(), user = &quot;username&quot;, password = &quot;password&quot;, host = &quot;host&quot;, port = port_number, dbname = &quot;database name&quot;) # This opens a connection called db to the info6270 SQLite database. # If the database doesn&#39;t exist, this code will also create it. library(RSQLite) con &lt;- dbConnect(drv = SQLite(), dbname= &quot;C:/info6270.db&quot;) Once the connection is established, you can interact with the database with the same functions presented in the MySQL example above. # lists table in the database access through the db connection. dbListTables(con) # liste fields from a table dbListFields(con,&quot;table_name&quot;) # import the results of a SQL query data &lt;- dbGetQuery(con, &quot;SQL query&quot;) # import all the data from a table data &lt;- dbReadTable(con, &quot;table name&quot;) # upload a data frame to a table (change options as needed) dbWriteTable(con, data, &quot;table name&quot;, row.names=FALSE, overwrite = FALSE, append = TRUE) Tidy your data Now we know how to import data into R. However, not all data comes in a nice and tidy shape, even if the data is already shaped like a table. In this section, well explore how to change the structure of your data frames with tidyr (https://tidyr.tidyverse.org/). Reshape data The reshape functions include pivot_longer() and its opposite, pivot_wider(). Lets look at how they work. First we create a tibble with the amount of funding received by some universities from the Canadian Tri-council. # This creates a funding tibble with 4 columns and some data. funding &lt;- tibble(university = as.character(c(&quot;DAL&quot;,&quot;SMU&quot;,&quot;SFX&quot;)), SSHRC = as.numeric(sample(1:100,3)), NSERC = as.numeric(sample(1:100,3)), CIHR = as.numeric(sample(1:100,3))) # Note: the sample(1:100,3) function randomly chooses three values between 1 and 100. pivot_longer() The pivot_longer() function makes your data longer by appending multiple columns together in two column. funding = pivot_longer(funding, cols = c(&quot;SSHRC&quot;,&quot;NSERC&quot;,&quot;CIHR&quot;), names_to = &quot;funder&quot;, values_to = &quot;funding_amount&quot;) funding ## # A tibble: 9 x 3 ## university funder funding_amount ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL SSHRC 39 ## 2 DAL NSERC 21 ## 3 DAL CIHR 39 ## 4 SMU SSHRC 97 ## 5 SMU NSERC 68 ## 6 SMU CIHR 49 ## 7 SFX SSHRC 45 ## 8 SFX NSERC 38 ## 9 SFX CIHR 48 pivot_wider() The pivot_wider() function does the opposite of pivot_longer() and takes a column with names and another with values and creates a new column for each name and storing the value in it. The following example will perhaps make this clearer. funding = pivot_wider(funding, names_from = funder, values_from = funding_amount) funding ## # A tibble: 3 x 4 ## university SSHRC NSERC CIHR ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 DAL 39 21 39 ## 2 SMU 97 68 49 ## 3 SFX 45 38 48 Expand tables Lets create a new funding tibble to explore some more tidyr functions. funding &lt;- tibble(university = as.character(c(&quot;DAL&quot;,&quot;DAL&quot;,&quot;DAL&quot;,&quot;SMU&quot;,&quot;SMU&quot;,&quot;SFX&quot;,&quot;SFX&quot;)), funder = as.character(c(&quot;SSHRC&quot;,&quot;NSERC&quot;,&quot;CIHR&quot;,&quot;SSHRC&quot;,&quot;CIHR&quot;,&quot;NSERC&quot;,&quot;CIHR&quot;)), n_grants = as.numeric(sample(1:100, 7))) funding ## # A tibble: 7 x 3 ## university funder n_grants ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL SSHRC 57 ## 2 DAL NSERC 56 ## 3 DAL CIHR 47 ## 4 SMU SSHRC 100 ## 5 SMU CIHR 61 ## 6 SFX NSERC 88 ## 7 SFX CIHR 96 expand() The expand() function creates all possible combinations of elements contained in a two or more columns indicated in the functions argument and drops other columns. The example below returns the possible combinations of universities and funders in the funding tibble we created. You can see that the SMU - NSERC combination and the SFX - SSHRC combination appear even though they are not present in the funding tibble. expand(funding, university, funder) ## # A tibble: 9 x 2 ## university funder ## &lt;chr&gt; &lt;chr&gt; ## 1 DAL CIHR ## 2 DAL NSERC ## 3 DAL SSHRC ## 4 SFX CIHR ## 5 SFX NSERC ## 6 SFX SSHRC ## 7 SMU CIHR ## 8 SMU NSERC ## 9 SMU SSHRC complete() The complete function does the same thing as the expand() function but it keeps the columns not provided to the function. funding = complete(funding, university, funder) funding ## # A tibble: 9 x 3 ## university funder n_grants ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL CIHR 47 ## 2 DAL NSERC 56 ## 3 DAL SSHRC 57 ## 4 SFX CIHR 96 ## 5 SFX NSERC 88 ## 6 SFX SSHRC NA ## 7 SMU CIHR 61 ## 8 SMU NSERC NA ## 9 SMU SSHRC 100 Handle missing values Sometimes your dataset is incomplete for one reason or another. Such a reason could be a participant to a survey that did not complete the survey or answer all the questions. What to do with the missing values or incomplete records depends on the nature of the data and the goal of your analysis. drop_na() The drop_na() function is useful to remove incomplete observations in the data (i.e., rows for which one of the column contains no value. The code below includes a statement that removes all incomplete observations, and one where we specify the columns names that should be scanned for NA values (the rows wont be deleted if there are NAs in the other columns). # This removes all incomplete observations drop_na(funding) ## # A tibble: 7 x 3 ## university funder n_grants ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL CIHR 47 ## 2 DAL NSERC 56 ## 3 DAL SSHRC 57 ## 4 SFX CIHR 96 ## 5 SFX NSERC 88 ## 6 SMU CIHR 61 ## 7 SMU SSHRC 100 # This would remove rows where the n_grants column is null and ignore null values in other # columns. drop_na(funding, n_grants) ## # A tibble: 7 x 3 ## university funder n_grants ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL CIHR 47 ## 2 DAL NSERC 56 ## 3 DAL SSHRC 57 ## 4 SFX CIHR 96 ## 5 SFX NSERC 88 ## 6 SMU CIHR 61 ## 7 SMU SSHRC 100 replace_na() You might just want to replace empty cells with a specific value (e.g., 0). # You have to provide the columns for which you want to replace NAs and the values to replace the NAs with in a list, so you can include as many columns as you want. replace_na(funding,list(n_grants = 0)) ## # A tibble: 9 x 3 ## university funder n_grants ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 DAL CIHR 47 ## 2 DAL NSERC 56 ## 3 DAL SSHRC 57 ## 4 SFX CIHR 96 ## 5 SFX NSERC 88 ## 6 SFX SSHRC 0 ## 7 SMU CIHR 61 ## 8 SMU NSERC 0 ## 9 SMU SSHRC 100 Note: that replacing null values with zeros for a numerical variable may seems logical, and it may be appropriate for your intended purpose. However, nulls and zeros are not logically equivalent: null implies the absence of data (somethings that we did not or could not observe), and zeros imply an observed or measured value of 0. Merge and split cells Lets create a simple tibble with some names. t &lt;- tibble(first_name = as.character(c(&quot;Jos&quot;,&quot;May&quot;)), last_name = as.character(c(&quot;Louis&quot;,&quot;West&quot;))) t ## # A tibble: 2 x 2 ## first_name last_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Jos Louis ## 2 May West unite() In some scenario, it may be more useful to have the first names and last names combined into a full_name column. This can be achieved with the unite() function. t = unite(t, &quot;first_name&quot;,&quot;last_name&quot;, # columns to unite. col = &quot;full_name&quot;, # name of the new column. sep = &quot; &quot;) # specifies that we want to seperate the first and last name with a space. t ## # A tibble: 2 x 1 ## full_name ## &lt;chr&gt; ## 1 Jos Louis ## 2 May West separate() In the opposite scenario where you have a full_name column but would rather have a first_name and a last_name column, you can use the separate() function to do that. t = separate(t, full_name, # column to separate. sep = &quot; &quot;, # character string to use as separator. into = c(&quot;first_name&quot;, &quot;last_name&quot;)) # names of the new columns. t ## # A tibble: 2 x 2 ## first_name last_name ## &lt;chr&gt; &lt;chr&gt; ## 1 Jos Louis ## 2 May West separate_rows() The separate_row() function is similar to the separate() funciton, but instead of creating new columns it creates new rows. Here is an example. # This creates some tibble contain names of authors in a single cell with a separator. t = tibble(article = as.character(c(&quot;awesome article&quot;,&quot;boring article&quot;)), authors = as.character(c(&quot;Toze, S.; Brown, A.&quot;,&quot;Smith, J.; Roberts, J.&quot;))) t ## # A tibble: 2 x 2 ## article authors ## &lt;chr&gt; &lt;chr&gt; ## 1 awesome article Toze, S.; Brown, A. ## 2 boring article Smith, J.; Roberts, J. t = separate_rows(t,authors, sep = &quot;; &quot;) t ## # A tibble: 4 x 2 ## article authors ## &lt;chr&gt; &lt;chr&gt; ## 1 awesome article Toze, S. ## 2 awesome article Brown, A. ## 3 boring article Smith, J. ## 4 boring article Roberts, J. Nested data The XML file import mentioned earlier is a good opportunity to explore the process of tidying nested data. converting an XML file to the tidy format requires quite a few steps. Here is a pretty standard, step by step process that you can follow whenever you are dealing with XML files. # load the xml 2 packages library(xml2) # read the xml file xml = read_xml(&quot;https://data.novascotia.ca/api/views/2d4m-9e6x/rows.xml&quot;) # the xml object is storing the data in its original xml format. # you can verify that by writing the xml object to a file and looking at it write_xml(xml, file=&quot;c:/data/xml.xml&quot;) # the xml2 package provides a function (as_list) to convert XML documents into an equivalent R list. # Attention, as_list should not be confused with as.list, which is a base R function that we used before. list &lt;- as_list(xml) The next step is converting that list into a tibble. So lets do that. public_housing &lt;- as_tibble(list) public_housing ## # A tibble: 1 x 1 ## response ## &lt;named list&gt; ## 1 &lt;named list [342]&gt; At the moment it has only one column called response of the named_list type, containing a single cell with 342 named list. This is a nested structure, where a single cell contains a list that contains other lists that contain other lists. unnest_longer() So, lets unnest the data in the response column using the unnest_longer() function. This function makes the tibble longer by expaning it vertically (adding rows) with the unnested data. public_housing = unnest_longer(public_housing, response) public_housing ## # A tibble: 342 x 2 ## response response_id ## &lt;named list&gt; &lt;chr&gt; ## 1 &lt;named list [22]&gt; row ## 2 &lt;named list [22]&gt; row ## 3 &lt;named list [21]&gt; row ## 4 &lt;named list [22]&gt; row ## 5 &lt;named list [22]&gt; row ## 6 &lt;named list [21]&gt; row ## 7 &lt;named list [22]&gt; row ## 8 &lt;named list [22]&gt; row ## 9 &lt;named list [22]&gt; row ## 10 &lt;named list [22]&gt; row ## # ... with 332 more rows Now were making progress. We have 342 observations each occupying one line. This is one of the tidy criteria! However, the columns are not right. We can see that there are two columns. The first one appears to contain 342 list of 22 elements, which are probably the 22 variables that we want as our columns. unnest_wider() Lets unnest these 342 lists using the unnest_wider() function. This function makes the tibble wider by expaning it horizontally (adding columns) with the unnested data. public_housing = unnest_wider(public_housing, response) public_housing ## # A tibble: 342 x 22 ## id property_project pid name address city postal_code number_of_floors ## &lt;lis&gt; &lt;list&gt; &lt;lis&gt; &lt;lis&gt; &lt;list&gt; &lt;lis&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 2 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 3 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;NULL&gt; &lt;list [1]&gt; ## 4 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 5 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 6 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;NULL&gt; &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 7 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 8 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 9 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## 10 &lt;lis~ &lt;list [1]&gt; &lt;lis~ &lt;lis~ &lt;list ~ &lt;lis~ &lt;list [1]&gt; &lt;list [1]&gt; ## # ... with 332 more rows, and 14 more variables: residential_units &lt;list&gt;, ## # housing_authority &lt;list&gt;, county &lt;list&gt;, elevator &lt;list&gt;, oil_heat &lt;list&gt;, ## # electric_heat &lt;list&gt;, public_water &lt;list&gt;, well &lt;list&gt;, sewer &lt;list&gt;, ## # onsite_septic &lt;list&gt;, municipality &lt;list&gt;, x_coordina &lt;list&gt;, ## # y_coordina &lt;list&gt;, response_id &lt;chr&gt; we can now see that each cell is a list of 1 element. unnest() Now lets unnest the data contained in each cell with the unnest() function. public_housing = unnest(public_housing, c(id, property_project, pid, name, address, city, postal_code, number_of_floors, residential_units, housing_authority, county, elevator, oil_heat, electric_heat, public_water, well, sewer, onsite_septic, municipality, x_coordina, y_coordina)) This seems silly there has to be a leaner way of writing this. Yes, there is. The names() returns a vector of the column names of a data frame. So we can use this much leaner code: colnames = names(public_housing) public_housing = unnest(public_housing, colnames) public_housing ## # A tibble: 342 x 22 ## id property_project pid name address city postal_code number_of_floors ## &lt;lis&gt; &lt;list&gt; &lt;lis&gt; &lt;lis&gt; &lt;list&gt; &lt;lis&gt; &lt;list&gt; &lt;list&gt; ## 1 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 2 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 3 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;NULL&gt; &lt;chr [1]&gt; ## 4 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 5 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 6 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;NULL&gt; &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 7 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 8 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 9 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## 10 &lt;chr~ &lt;chr [1]&gt; &lt;chr~ &lt;chr~ &lt;chr [~ &lt;chr~ &lt;chr [1]&gt; &lt;chr [1]&gt; ## # ... with 332 more rows, and 14 more variables: residential_units &lt;list&gt;, ## # housing_authority &lt;list&gt;, county &lt;list&gt;, elevator &lt;list&gt;, oil_heat &lt;list&gt;, ## # electric_heat &lt;list&gt;, public_water &lt;list&gt;, well &lt;list&gt;, sewer &lt;list&gt;, ## # onsite_septic &lt;list&gt;, municipality &lt;list&gt;, x_coordina &lt;list&gt;, ## # y_coordina &lt;list&gt;, response_id &lt;chr&gt; We now have a tibble with 342 observation of 22 variables. Looks good! But the values in the cells still dont look right. Theres just one more round of unnesting to apply to all the cell using the same code as in the last step. public_housing = unnest(public_housing, colnames) public_housing ## # A tibble: 342 x 22 ## id property_project pid name address city postal_code number_of_floors ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 117 330101X 6503~ Rive~ 19/27/~ Pict~ B0K 1S0 2 ## 2 324 200214X 5006~ Bell~ 10 Gra~ Gran~ B0E 1L0 2 ## 3 247 100215X 1511~ Sydn~ 77 Ain~ Sydn~ &lt;NA&gt; 1 ## 4 337 390201X 2522~ Elgi~ 22 Elg~ Spri~ B0M 1X0 1 ## 5 224 100201X 1513~ Will~ 10 Wil~ Sydn~ B1N 1R4 2 ## 6 289 150226X 1524~ 198 ~ &lt;NA&gt; Flor~ B0C 1J0 2 ## 7 214 612301 9021~ Trin~ 3 Trin~ Yarm~ B5A 1P3 2 ## 8 143 350801 2017~ Youn~ 130 Yo~ Truro B2N 3X4 2 ## 9 104 740101 6018~ Ritc~ 3809 H~ Rive~ B0J 2W0 2 ## 10 174 430901 4017~ Dr. ~ 3792 N~ Hali~ B3K 3G5 9 ## # ... with 332 more rows, and 14 more variables: residential_units &lt;chr&gt;, ## # housing_authority &lt;chr&gt;, county &lt;chr&gt;, elevator &lt;chr&gt;, oil_heat &lt;chr&gt;, ## # electric_heat &lt;chr&gt;, public_water &lt;chr&gt;, well &lt;chr&gt;, sewer &lt;chr&gt;, ## # onsite_septic &lt;chr&gt;, municipality &lt;chr&gt;, x_coordina &lt;chr&gt;, ## # y_coordina &lt;chr&gt;, response_id &lt;chr&gt; Wow. Now it looks really good! But wait theres one more thing. Look at the data types of the columns. They are all characters, which doesnt seem right because some of our columns appear to contain only numerical data. The readr package comes to the rescue with its easy to use type_convert() function. public_housing = type_convert(public_housing) public_housing ## # A tibble: 342 x 22 ## id property_project pid name address city postal_code ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 117 330101X 65032708 Riverton Hei~ 19/27/29 Ri~ Picto~ B0K 1S0 ## 2 324 200214X 50067362 Bellevue 10 Grand Et~ Grand~ B0E 1L0 ## 3 247 100215X 15113962 Sydney Senio~ 77 Ainsley ~ Sydney &lt;NA&gt; ## 4 337 390201X 25227687 Elgin Street~ 22 Elgin St~ Sprin~ B0M 1X0 ## 5 224 100201X 15130651 William Stre~ 10 William ~ Sydney B1N 1R4 ## 6 289 150226X 15242738 198 Pitt Str~ &lt;NA&gt; Flore~ B0C 1J0 ## 7 214 612301 90212812 Trinity Place 3 Trinity P~ Yarmo~ B5A 1P3 ## 8 143 350801 20178653 Young St. Lo~ 130 Young S~ Truro B2N 3X4 ## 9 104 740101 60187283 Ritcey&#39;s Cov~ 3809 Hwy. 3~ River~ B0J 2W0 ## 10 174 430901 40177982 Dr. Prince M~ 3792 Novale~ Halif~ B3K 3G5 ## # ... with 332 more rows, and 15 more variables: number_of_floors &lt;dbl&gt;, ## # residential_units &lt;dbl&gt;, housing_authority &lt;chr&gt;, county &lt;chr&gt;, ## # elevator &lt;chr&gt;, oil_heat &lt;chr&gt;, electric_heat &lt;chr&gt;, public_water &lt;chr&gt;, ## # well &lt;chr&gt;, sewer &lt;chr&gt;, onsite_septic &lt;chr&gt;, municipality &lt;chr&gt;, ## # x_coordina &lt;dbl&gt;, y_coordina &lt;dbl&gt;, response_id &lt;chr&gt; We have now converted an XML document into an easy to use tidy dataset! Here is the entire process that we just went through in a single chunk of code. xml = read_xml(&quot;https://data.novascotia.ca/api/views/2d4m-9e6x/rows.xml&quot;) list = as_list(xml) public_housing = as_tibble(list) public_housing = unnest_longer(public_housing, response) public_housing = unnest_wider(public_housing, response) public_housing = unnest(public_housing, cols = names(public_housing)) public_housing = unnest(public_housing, cols = names(public_housing)) public_housing = type_convert(public_housing) Combine dataframes Sometimes the data will come in separate files so you will have to combine the pieces into a single and tidy dataset. bind_rows() bind rows concatenates data frames vertically, adding new columns when column names differ between data frames. # Create three data frames data1 &lt;- data.frame(x1 = 1:5, x2 = letters[1:5]) data2 &lt;- data.frame(x1 = 2:6, x2 = letters[2:6]) data3 &lt;- data.frame(x1 = 3:7, x4 = letters[3:7]) # Apply bind_rows function bind_rows(data1, data2) ## x1 x2 ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e ## 6 2 b ## 7 3 c ## 8 4 d ## 9 5 e ## 10 6 f bind_cols() The bind_cols() function concatenates the entire data frames horizontally. The number of rows in the two databases must be the same. # Apply bind_rows function bind_cols(data1, data3) ## x1...1 x2 x1...3 x4 ## 1 1 a 3 c ## 2 2 b 4 d ## 3 3 c 5 e ## 4 4 d 6 f ## 5 5 e 7 g Join dataframes The join family of functions is used to combine rows and columns of data frames based on a matching criteria. left_join() The left_join() function returns all records from the first data frame and only records from the second data frame for which the matching condition is TRUE. Here is an example: left_join(data1, data3, by=&quot;x1&quot;) ## x1 x2 x4 ## 1 1 a &lt;NA&gt; ## 2 2 b &lt;NA&gt; ## 3 3 c c ## 4 4 d d ## 5 5 e e right_join() The right_join() function is returns all records from the second data frame and only records from the first data frame for which the matching condition is TRUE. Here is an example: inner_join() The inner_join() function returns only records for which the matching condition is TRUE. Here is an example: inner_join(data1, data3, by=&quot;x1&quot;) ## x1 x2 x4 ## 1 3 c c ## 2 4 d d ## 3 5 e e anti_join() The anti_join() function is useful if you want to exclude observations (rows) in your tibble when the matching condition is TRUE. anti_join(data1, data2, by=&quot;x1&quot;) ## x1 x2 ## 1 1 a full_join() The full join is essentially a combination of the left_join() and right_join() functions. full_join(data1, data3, by=&quot;x1&quot;) ## x1 x2 x4 ## 1 1 a &lt;NA&gt; ## 2 2 b &lt;NA&gt; ## 3 3 c c ## 4 4 d d ## 5 5 e e ## 6 6 &lt;NA&gt; f ## 7 7 &lt;NA&gt; g Note: You can use the functions without specifying the column(s) to use for the matching. In this case, all columns with the same names will be used for the matching. inner_join(data1, data2) ## x1 x2 ## 1 2 b ## 2 3 c ## 3 4 d ## 4 5 e Rename variables rename(data1, banana = x1, apple = x2) ## banana apple ## 1 1 a ## 2 2 b ## 3 3 c ## 4 4 d ## 5 5 e Select variables The select() variable is used to retrieve a subset of columns from a dataframe or tibble. # Select the column x1 from the data1 dataframe. select(data1, x1) ## x1 ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 # This selects the column x1 from the data1 dataframe AND renames it to Banana. select(data1, banana = x1) ## banana ## 1 1 ## 2 2 ## 3 3 ## 4 4 ## 5 5 Filter rows The filter() functions is used to retrieve a subset of rows from a dataframe or tibble based on some criteria. # select observation for which the value of x1 is lower than 3. filter(data1, x1 &lt; 3) ## x1 x2 ## 1 1 a ## 2 2 b # you can use the %in% operator to select observations for which the value is in a list. filter(data1, x2 %in% c(&quot;b&quot;,&quot;d&quot;,&quot;e&quot;)) ## x1 x2 ## 1 2 b ## 2 4 d ## 3 5 e Modify or create new variables The mutate() function is used to create a new variable or update an existing one. # This adds a column called x4 that contains the value of column 1 multiplied by 2. mutate(data1, x4 = x1*2) ## x1 x2 x4 ## 1 1 a 2 ## 2 2 b 4 ## 3 3 c 6 ## 4 4 d 8 ## 5 5 e 10 # This updates the already existing variable x1 with the original value multiplied by 2. mutate(data1, x1 = x1*2) ## x1 x2 ## 1 2 a ## 2 4 b ## 3 6 c ## 4 8 d ## 5 10 e Export data Now that you have a nice tidy data set, you may want to export it so you can save it for future use and not have to repeat the data collection and tidying process, or maybe because you want to share it with others. Export dataframes Exporting data frames is very easy in R (the hardest part was getting there). The readr package has a bunch of functions to write files. Here are examples: # You can test this code with any dataframe or tibble that you have created. library(readr) write_csv(df, file = &quot;filename.csv&quot;, col_names = TRUE) write_csv2(df, file = &quot;filename.csv&quot;, col_names = TRUE) #write_csv2 uses the european format (commas instead of dot for decimals, and semicolon as delimiter) write_tsv(df, file = &quot;filename.tsv&quot;, col_names = TRUE) write_delim(df, file = &quot;filename.txt&quot;, delim = &quot;\\t&quot;, col_names = TRUE) JSON Writing JSON files from a data frame with the toJSON() function is just as easy as reading them with the fromJSON() function. # let&#39;s read a csv file and convert it to a JSON file titanic &lt;- read_csv(&quot;https://pmongeon.github.io/info6270/files/data/titanic.csv&quot;) # The pretty=TRUE argument spaces out the JSON file so it is more readable for humans. write_file(toJSON(titanic, pretty=TRUE), &quot;titanic.json&quot;) The Pipe The dplyr and maggritr packages (automatically loaded with the tidyverse) include an extremely useful and popular operator called the pipe which looks like this in R: %&gt;%. The pipe is a wonderful tool for building lean code that are easier to read and to debug. Dont let the small size of this section mislead you. The pipe is an extremely useful feature of the tidyverse, and learning how to code with it can drastically change your experience as a coder, and the experience of those who will read or use your code too. library(data.table) library(httr) # I&#39;m storing the url for the api call in an object to make the code below more readable. url&lt;-&quot;https://openlibrary.org/api/books?bibkeys=OLID:OL22123296M&amp;format=json&quot; data = GET(url) df = content(data) df = as_tibble(rbindlist(df)) df ## # A tibble: 1 x 4 ## bib_key info_url preview preview_url ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 OLID:OL22123296M https://openlibrary.org/b~ noview https://openlibrary.org/b~ # This is the embedded version of the same process as above url &lt;- &quot;https://openlibrary.org/api/books?bibkeys=OLID:OL22123296M&amp;format=json&quot; data = as_tibble(rbindlist(content(GET(url)))) data ## # A tibble: 1 x 4 ## bib_key info_url preview preview_url ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 OLID:OL22123296M https://openlibrary.org/b~ noview https://openlibrary.org/b~ library(httr) library(data.table) # This is the same process but written with the pipe. url &lt;- &quot;https://openlibrary.org/api/books?bibkeys=OLID:OL22123296M&amp;format=json&quot; data = url %&gt;% GET() %&gt;% content() %&gt;% rbindlist() %&gt;% as_tibble() data ## # A tibble: 1 x 4 ## bib_key info_url preview preview_url ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 OLID:OL22123296M https://openlibrary.org/b~ noview https://openlibrary.org/b~ Additional resources There are many cheatsheets available for R packages that can be very useful to quickly see what the different functions of the packages can do. Homework Your homework for this chapter is to complete lab #2 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
